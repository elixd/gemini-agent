# Vision: The Proactive Personal Agent

## 1. Core Philosophy

This project aims to create a **proactive, context-aware personal AI agent**. It should feel less like a command-line tool and more like a personal assistant that understands the user's current context and priorities. The agent is designed for a single user, prioritizing simplicity and direct file-based integration over complex, scalable infrastructure.

## 2. The Three-Tier Context Architecture

The agent's "world awareness" is constructed on-the-fly for every user request. It is a block of text assembled from three distinct tiers of context. For a concrete example of the final text block, see `world_awareness_example.md`.

### Tier 1: The Unconditional Dashboard (Always On)
This context is provided to the agent with every single interaction, regardless of the user's specific request. It represents the agent's baseline reality.

*   **Static Components:**
    *   **System Prompt:** Defines the agent's core identity, purpose, and constraints.
    *   **Tool Manifest:** A machine-readable list of available tools and their usage.
*   **Dynamic Components:**
    *   **Time & Task Awareness:** Current Date & Time; a list of all scheduled tasks.
    *   **External World Awareness (Future):** Summaries of calendar events, emails, etc. These will be prepared by external helper scripts and read by the agent.
    *   **Project & Note Awareness:** A list of all active note files.

### Tier 2: The Conditional Briefing (Prompt-Driven)
After the user provides a prompt, a preliminary "Briefing Assistant" (which can be a separate, lightweight LLM call or a rule-based system) analyzes the request and assembles additional, relevant context. This is a form of advanced, targeted RAG (Retrieval-Augmented Generation).

*   **Example:** If the user mentions a specific project, the Briefing Assistant will retrieve the content of the corresponding note file and add it to the context *before* the main agent begins its reasoning process.

### Tier 3: Agent-Driven Context (Reactive)
This context is generated by the main agent itself during its reasoning loop (e.g., a ReAct cycle). If the information provided in Tiers 1 and 2 is insufficient, the agent can decide to use its tools to find more information.

*   **Example:** If the user asks a question not covered by the dashboard or briefing, the agent can choose to use a tool (like reading a file). The output of that tool is then added to the context, and the agent uses this new information to form its final answer.

## 3. Architectural Principles

This vision directly influences our architecture:

*   **Framework-First:** We will use an agent framework (like LangChain) to manage the complexities of prompt assembly, tool integration, reasoning loops (Tier 3), and conversational memory.
*   **Modularity is Key:** The logic for fetching each piece of the Dynamic Dashboard (Tier 1) and the Conditional Briefing (Tier 2) must be a separate, self-contained module.
*   **Simplicity (Personal Use):** We will prefer simple, file-based data stores (`.json`, `.md`) over databases wherever possible. Helper agents or scripts will run periodically and write their outputs to local text files for the main agent to consume.

This document will be updated as our vision for the agent evolves.

## 4. Future Capabilities & Use Cases

This architecture is designed to support a wide range of powerful, proactive interactions. Examples of future capabilities include:

*   **Guided Reviews:** The user can ask, "Let's do our weekly review." The agent, via a scheduled job, can then prompt the user with a series of questions (e.g., "What went well this week?", "What were the biggest challenges?") and compile the answers into a new note.
*   **Automated Journaling:** The user can ask the agent to prompt them every evening to record their thoughts. The agent can then use a dedicated `append_to_diary` tool to log the user's responses in a running diary file.
*   **Personalized Affirmations:** The user can ask, "Tell me something positive every morning." The agent will schedule a daily job to send an uplifting or personalized message to the user at the start of their day.
*   **Meeting Preparation:** By combining calendar awareness (Tier 1) and the ability to read notes (Tier 2), the agent could proactively summarize the relevant project note 30 minutes before a scheduled meeting and remind the user of the key points.

## 5. Examples of how it can be used:
- what time it is? (it would replay based on its dashboard info)
- what time is it in New York (makes a tool call and replies based on that)


## 6. Some implementation Ideas

### managing agent working memory / context
While it may not always neccesary to load every note and cocumtn in the context all the time. I think the agent might be able to add some files/notes/emails etc to context. not just make a fucntion call to read a note once, but request it to be kept ints context untill it says otherwise or untill the user says otherwise. for example i want to discuss some project with the agent. the agemt wll request it to be added to context 

### Context Caching Considerations
there is LLM provider level context caching. it only works if the promt prefix that is sent to llm stays the same. therefore it makes sense to keep static content in the beginning of the prompt and new/dynanic content at the end. For example, system prompt, then chat distory, and then current date-time. this way system prompt and chat history will hit cache. 





