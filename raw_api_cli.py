import os
import json
import requests
import argparse
from dotenv import load_dotenv

from core.persistent_memory import read_memory

# --- Configuration ---
load_dotenv()
API_KEY = os.getenv("OPENROUTER_API_KEY")
MODEL_NAME = "google/gemini-2.5-flash"
API_URL = "https://openrouter.ai/api/v1/chat/completions"

# --- Manually Defined Tool Manifest ---
# This manifest is now structured to exactly match the one generated by LangChain.
TOOLS_MANIFEST = [
    {
        "type": "function",
        "function": {
            "name": "run_shell_command",
            "description": "Executes a shell command.",
            "parameters": {
                "type": "object",
                "properties": {"command": {"type": "string"}},
                "required": ["command"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "list_directory",
            "description": "Lists the files and subdirectories within a specified directory.",
            "parameters": {
                "type": "object",
                "properties": {"path": {"type": "string"}},
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "Reads and returns the content of a specified file.",
            "parameters": {
                "type": "object",
                "properties": {"file_path": {"type": "string"}},
                "required": ["file_path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "description": "Writes content to a specified file.",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {"type": "string"},
                    "content": {"type": "string"},
                },
                "required": ["file_path", "content"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "save_memory",
            "description": "Saves a specific fact to the agent's long-term memory.\nUse this when the user explicitly asks you to remember something.\nThis tool just returns the fact. The graph is responsible for saving it.",
            "parameters": {
                "type": "object",
                "properties": {"fact": {"type": "string"}},
                "required": ["fact"],
            },
        },
    },
]


def make_raw_api_call(messages):
    """Makes a direct call to the OpenRouter API and prints the raw response."""
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    payload = {"model": MODEL_NAME, "messages": messages, "tools": TOOLS_MANIFEST}

    print("--- Sending Raw API Request ---")
    print(json.dumps(payload, indent=2))
    print("-" * 30)

    try:
        response = requests.post(API_URL, headers=headers, json=payload)
        response.raise_for_status()
        print("--- Received Naked API Response ---")
        print(json.dumps(response.json(), indent=2))
        print("-" * 30)
    except requests.exceptions.RequestException as e:
        print(f"An error occurred: {e}")
        if e.response:
            print("Response content:", e.response.text)


def main():
    """The main entry point for the raw API CLI tool."""
    parser = argparse.ArgumentParser(description="A raw CLI to test model responses.")
    parser.add_argument("message", nargs="*", help="Message to send to the model.")
    args = parser.parse_args()

    with open("core/system_prompt.md", "r") as f:
        system_prompt_template = f.read()

    memory = read_memory()
    system_prompt = system_prompt_template
    if memory:
        system_prompt += f"\n\n# User-Specific Memory\n" + "\n".join(f"- {fact}" for fact in memory)

    messages = [{"role": "system", "content": system_prompt}]

    if args.message:
        messages.append({"role": "user", "content": " ".join(args.message)})
        make_raw_api_call(messages)
    else:
        print("Raw API CLI is running. Type 'exit' or 'quit' to end.")
        while True:
            input_text = input("You: ")
            if input_text.lower() in ["exit", "quit"]:
                break
            messages.append({"role": "user", "content": input_text})
            make_raw_api_call(messages)
            # In interactive mode, we only keep the last user message for the next turn
            messages.pop()


if __name__ == "__main__":
    main()
